# pytorch_lightning==2.0.1
seed_everything: 0
optimizer: 
  class_path: torch.optim.AdamW
  init_args:
    lr: 1.0e-4
    weight_decay: 1.0e-2

model:
  class_path: models.TransformerCA.TransformerCA
  init_args:
        # n_channels is injected by train.py
    flatten_temporal_dimension: true
    loss_function: FocalDice
    d_model: 160
    nhead: 4
    num_layers: 3
    kernel_size: 3
    dilations: [1, 2, 4, 8]
    dropout: 0.3
    use_doy: true
    physics_loss_weight: 1.0
    physics_kernel_size: 7
    use_temporal_attention: true
    # n_leading_observations is injected by train.py

data:
  data_dir: ../data/hdf5/
  batch_size: 2
  n_leading_observations: 5
  crop_side_length: 128
  load_from_hdf5: true
  num_workers: 8
  remove_duplicate_features: false
  features_to_keep: null
  n_leading_observations_test_adjustment: 5
  return_doy: true
  
do_train: true
do_test: true
do_predict: false
